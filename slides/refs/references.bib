@article{langford_2015, 
title={Spatiotemporal dynamics of wetted soils across a polar desert landscape}, volume={27}, 
DOI={10.1017/S0954102014000601}, 
number={2}, 
journal={Antarctic Science}, 
publisher={Cambridge University Press}, 
author={Langford, Zachary L. and Gooseff, Michael N. and Lampkin, Derrick J.}, year={2015}, 
pages={197--209}}

@InProceedings{Zhou_2018_CVPR,
author = {Zhou, Peng and Han, Xintong and Morariu, Vlad I. and Davis, Larry S.},
title = {Learning Rich Features for Image Manipulation Detection},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
} 

@InProceedings{Sreepathi_IEEE-Cluster_20170905,
 author		= {Sarat Sreepathi and Jitendra Kumar and Richard T. Mills and Forrest M. Hoffman and Vamsi Sripathi and William W. Hargrove},
 title		= {Parallel Multivariate Spatio-Temporal Clustering of Large Ecological Datasets on Hybrid Supercomputers},
 booktitle	= {Proceedings of the 19th IEEE International Conference on Cluster Computing (Cluster 2017)},
 organization	= {Institute of Electrical and Electronics Engineers (IEEE)},
 address	= {Honolulu, Hawai`i, USA},
 pages		= {267--277},
 doi		= {10.1109/CLUSTER.2017.88},
 day		= 5,
 month		= sep,
 year		= 2017,
 abstract	= {A proliferation of data from vast networks of remote sensing platforms (satellites, unmanned aircraft systems (UAS), airborne etc.), observational facilities (meteorological, eddy covariance etc.), state-of-the-art sensors, and simulation models offer unprecedented opportunities for scientific discovery. Unsupervised classification is a widely applied data mining approach to derive insights from such data. However, classification of very large data sets is a complex computational problem that requires efficient numerical algorithms and implementations on high performance computing (HPC) platforms. Additionally, increasing power, space, cooling and efficiency requirements has led to the deployment of hybrid supercomputing platforms with complex architectures and memory hierarchies like the Titan system at Oak Ridge National Laboratory. The advent of such accelerated computing architectures offers new challenges and opportunities for big data analytics in general and specifically, large scale cluster analysis in our case. Although there is an existing body of work on parallel cluster analysis, those approaches do not fully meet the needs imposed by the nature and size of our large data sets. Moreover, they had scaling limitations and were mostly limited to traditional distributed memory computing platforms. We present a parallel Multivariate Spatio-Temporal Clustering (MSTC) technique based on k-means cluster analysis that can target hybrid supercomputers like Titan. We developed a hybrid MPI, CUDA and OpenACC implementation that can utilize both CPU and GPU resources on computational nodes. We describe performance results on Titan that demonstrate the scalability and efficacy of our approach in processing large ecological data sets.}
}

@Article{Langford_RemoteSens_20160906,
 author		= {Zachary Langford and Jitendra Kumar and Forrest M. Hoffman and Richard J. Norby and Stan D. Wullschleger and Victoria L. Sloan and Colleen M. Iversen},
 title		= {Mapping {A}rctic Plant Functional Type Distributions in the {B}arrow {E}nvironmental {O}bservatory Using {WorldView-2} and {LiDAR} Datasets},
 journal	= RemoteSens,
 volume		= 8,
 number		= 9,
 pages		= 733,
 doi		= {10.3390/rs8090733},
 day		= 6,
 month		= sep,
 year		= 2016,
 abstract	= {Multi-scale modeling of Arctic tundra vegetation requires characterization of the heterogeneous tundra landscape, which includes representation of distinct plant functional types (PFTs). We combined high-resolution multi-spectral remote sensing imagery from the WorldView-2 satellite with light detecting and ranging (LiDAR)-derived digital elevation models (DEM) to characterize the tundra landscape in and around the Barrow Environmental Observatory (BEO), a 3021-hectare research reserve located at the northern edge of the Alaskan Arctic Coastal Plain. Vegetation surveys were conducted during the growing season (June--August) of 2012 from 48 1\,m\,$\times$\,1\,m plots in the study region for estimating the percent cover of PFTs (i.e., sedges, grasses, forbs, shrubs, lichens and mosses). Statistical relationships were developed between spectral and topographic remote sensing characteristics and PFT fractions at the vegetation plots from field surveys. These derived relationships were employed to statistically upscale PFT fractions for our study region of 586 hectares at 0.25-m resolution around the sampling areas within the BEO, which was bounded by the LiDAR footprint. We employed an unsupervised clustering for stratification of this polygonal tundra landscape and used the clusters for segregating the field data for our upscaling algorithm over our study region, which was an inverse distance weighted (IDW) interpolation. We describe two versions of PFT distribution maps upscaled by IDW from WorldView-2 imagery and LiDAR: (1) a version computed from a single image in the middle of the growing season; and (2) a version computed from multiple images through the growing season. This approach allowed us to quantify the value of phenology for improving PFT distribution estimates. We also evaluated the representativeness of the field surveys by measuring the Euclidean distance between every pixel. This guided the ground-truthing campaign in late July of 2014 for addressing uncertainty based on representativeness analysis by selecting 24 1\,m\,$\times$\,1\,m plots that were well and poorly represented. Ground-truthing indicated that including phenology had a better accuracy ($R^2 = 0.75, RMSE = 9.94$) than the single image upscaling ($R^2 = 0.63, RMSE = 12.05$) predicted from IDW. We also updated our upscaling approach to include the 24 ground-truthing plots, and a second ground-truthing campaign in late August of 2014 indicated a better accuracy for the phenology model ($R^2 = 0.61, RMSE = 13.78$) than only using the original 48 plots for the phenology model ($R^2 = 0.23, RMSE = 17.49$). We believe that the cluster-based IDW upscaling approach and the representativeness analysis offer new insights for upscaling high-resolution data in fragmented landscapes. This analysis and approach provides PFT maps needed to inform land surface models in Arctic ecosystems.}
}

@Article{tc-10-2241-2016,
AUTHOR = {Kumar, J. and Collier, N. and Bisht, G. and Mills, R. T. and Thornton, P. E. and Iversen, C. M. and Romanovsky, V.},
TITLE = {Modeling the spatiotemporal variability in subsurface thermal regimes across a low-relief polygonal tundra landscape},
JOURNAL = {The Cryosphere},
VOLUME = {10},
YEAR = {2016},
NUMBER = {5},
PAGES = {2241--2274},
URL = {https://www.the-cryosphere.net/10/2241/2016/},
DOI = {10.5194/tc-10-2241-2016}
}

@Article{Hargrove_JGS_20060701,
 author		= {William W. Hargrove and Forrest M. Hoffman and Paul F. Hessburg},
 title		= {Mapcurves: A Quantitative Method for Comparing Categorical Maps},
 journal	= JGS,
 volume		= 8,
 number		= 2,
 pages          = {187--208},
 doi		= {10.1007/s10109-006-0025-x},
 day		= 1,
 month		= jul,
 year		= 2006,
 abstract	= {We present Mapcurves, a quantitative goodness-of-fit (GOF) method that unambiguously shows the degree of spatial concordance between two or more categorical maps. Mapcurves graphically and quantitatively evaluate the degree of fit among any number of maps and quantify a GOF for each polygon, as well as the entire map. The Mapcurve method indicates a perfect fit even if all polygons in one map are comprised of unique sets of the polygons in another map, if the coincidence among map categories is absolute. It is not necessary to interpret (or even know) legend descriptors for the categories in the maps to be compared, since the degree of fit in the spatial overlay alone forms the basis for the comparison. This feature makes Mapcurves ideal for comparing maps derived from remotely sensed images. A translation table is provided for the categories in each map as an output. Since the comparison is category-based rather than cell-based, the GOF is resolution-independent. Mapcurves can be applied either to entire map categories or to individual raster patches or vector polygons. Mapcurves also have applications for quantifying the spatial uncertainty of particular map features.}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}


@InProceedings{Langford_DMESS2017_20171118,
 author		= {Zachary L. Langford and Jitendra Kumar and Forrest M. Hoffman},
 title		= {Convolutional Neural Network Approach for Mapping Arctic Vegetation using Multi-Sensor Remote Sensing Fusion},
 booktitle	= {Proceedings of the 2017 {IEEE} International Conference on Data Mining Workshops ({ICDMW} 2017)},
 organization	= {Institute of Electrical and Electronics Engineers (IEEE)},
 publisher	= {Conference Publishing Services (CPS)},
 doi		= {10.1109/ICDMW.2017.48},
 day		= 18,
 month		= nov,
 year		= 2017,
 abstract	= {Accurate and high-resolution maps of vegetation are critical for projects seeking to understand the terrestrial ecosystem processes and land-atmosphere interactions in Arctic ecosystems, such as U.S.\ Department of Energy's Next Generation Ecosystem Experiment (NGEE) Arctic. However, most existing Arctic vegetation maps are at a coarse resolution and with a varying degree of detail and accuracy. Remote sensing-based approaches for mapping vegetation, while promising, are challenging in high latitude environments due to frequent cloud cover, polar darkness, and limited availability of high-resolution remote sensing datasets (e.g., $\sim$5~m). This study proposes a new remote sensing based multi-sensor data fusion approach for developing high-resolution maps of vegetation in the Seward Peninsula, Alaska. We focus detailed analysis and validation study around the Kougarok river, located in the central Seward Peninsula of Alaska.

We seek to evaluate the integration of hyper-spectral, multi-spectral, radar, and terrain datasets using unsupervised and supervised classification techniques over a $\sim$343.72~km$^{2}$ area for generating vegetation classifications at a variety of resolutions (5~m and 12.5~m). We fist applied a quantitative goodness-of-fit method, called Mapcurves, that shows the degree of spatial concordance between the public coarse resolution maps and $k$-means clustering values and relabels the $k$ values based on the best overlap. We develop a convolutional neural network (CNN) approach for developing high resolution vegetation maps for our study region in Arctic. We compare two CNN approaches: (1) breaking up the images into small patches (e.g., $6 \times 6$) and predict the vegetation class for entire patch and (2) semantic segmentation and predict the vegetation class for every pixel. We also perform accuracy assessments of the developed data products and evaluate varying CNN architectures. The fusion of hyperspectral and optical datasets performed the best, with accuracy values increased from 0.64 to 0.96--0.97 when using a training map produced by unsupervised clustering and Mapcurves labeling for both CNN models.}
}

@InProceedings{DB15a,
  author       = "J.T. Springenberg and A. Dosovitskiy and T. Brox and M. Riedmiller",
  title        = "Striving for Simplicity: The All Convolutional Net",
  booktitle    = "ICLR (workshop track)",
  year         = "2015",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2015/DB15a"
}

@InProceedings{Qu_2018_CVPR,
author = {Qu, Ying and Qi, Hairong and Kwan, Chiman},
title = {Unsupervised Sparse Dirichlet-Net for Hyperspectral Image Super-Resolution},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
} 


@InProceedings{pmlr-v80-ren18a,
  title = 	 {Learning to Reweight Examples for Robust Deep Learning},
  author = 	 {Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4334--4343},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/ren18a/ren18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/ren18a.html},
  abstract = 	 {Deep neural networks have been shown to be very powerful modeling tools for many supervised learning tasks involving complex input patterns. However, they can also easily overfit to training set biases and label noises. In addition to various regularizers, example reweighting algorithms are popular solutions to these problems, but they require careful tuning of additional hyperparameters, such as example mining schedules and regularization hyperparameters. In contrast to past reweighting methods, which typically consist of functions of the cost value of each example, in this work we propose a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions. To determine the example weights, our method performs a meta gradient descent step on the current mini-batch example weights (which are initialized from zero) to minimize the loss on a clean unbiased validation set. Our proposed method can be easily implemented on any type of deep network, does not require any additional hyperparameter tuning, and achieves impressive performance on class imbalance and corrupted label problems where only a small amount of clean validation data is available.}
}

@Article{rs9030298,
AUTHOR = {Wu, Hao and Prasad, Saurabh},
TITLE = {Convolutional Recurrent Neural Networks forHyperspectral Data Classification},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE NUMBER = {298},
URL = {http://www.mdpi.com/2072-4292/9/3/298},
ISSN = {2072-4292},
ABSTRACT = {Deep neural networks, such as convolutional neural networks (CNN) and stackedautoencoders, have recently been successfully used to extract deep features for hyperspectral dataclassification. Recurrent neural networks (RNN) are another type of neural networks, which arewidely used for sequence analysis because they are constructed to extract contextual information fromsequences by modeling the dependencies between different time steps. In this paper, we study theability of RNN for hyperspectral data classification by extracting the contextual information from thedata. Specifically, hyperspectral data are treated as spectral sequences, and an RNN is used to modelthe dependencies between different spectral bands. In addition, we propose to use a convolutionalrecurrent neural network (CRNN) to learn more discriminative features for hyperspectral dataclassification. In CRNN, a few convolutional layers are first learned to extract middle-level andlocally-invariant features from the input data, and the following recurrent layers are then employedto further extract spectrally-contextual information from the features generated by the convolutionallayers. Experimental results on real hyperspectral datasets show that our method provides betterclassification performance compared to traditional methods and other state-of-the-art deep learningmethods for hyperspectral data classification.},
DOI = {10.3390/rs9030298}
}

@article{RonnebergerFB15,
  author    = {Olaf Ronneberger and
               Philipp Fischer and
               Thomas Brox},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal   = {CoRR},
  volume    = {abs/1505.04597},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.04597},
  archivePrefix = {arXiv},
  eprint    = {1505.04597},
  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/RonnebergerFB15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Chen:2016,
 author = {Chen, Tianqi and Guestrin, Carlos},
 title = {XGBoost: A Scalable Tree Boosting System},
 booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {785--794},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939785},
 doi = {10.1145/2939672.2939785},
 acmid = {2939785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {large-scale machine learning},
} 

@InProceedings{Sze-To2017,
author="Sze-To, Antonio
and Wong, Andrew K. C.",
editor="Karray, Fakhri
and Campilho, Aur{\'e}lio
and Cheriet, Farida",
title="A Weight-Selection Strategy on Training Deep Neural Networks for Imbalanced Classification",
booktitle="Image Analysis and Recognition",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="3--10",
abstract="Deep Neural Networks (DNN) have recently received great attention due to their superior performance in many machining-learning problems. However, the use of DNN is still impeded, if the input data is imbalanced. Imbalanced classification refers to the problem that one class contains a much smaller number of samples than the others in classification. It poses a great challenge to existing classifiers including DNN, due to the difficulty in recognizing the minority class. So far, there are still limited studies on how to train DNN for imbalanced classification. In this study, we propose a new strategy to reduce over-fitting in training DNN for imbalanced classification based on weight selection. In training DNN, by splitting the original training set into two subsets, one used for training to update weights, and the other for validation to select weights, the weights that render the best performance in the validation set would be selected. To our knowledge, it is the first systematic study to examine a weight-selection strategy on training DNN for imbalanced classification. Demonstrated by experiments on 10 imbalanced datasets obtained from MNIST, the DNN trained by our new strategy outperformed the DNN trained by a standard strategy and the DNN trained by cost-sensitive learning with statistical significance (p = 0.00512). Surprisingly, the DNN trained by our new strategy was trained on 20{\%} less training images, corresponding to 12,000 less training images, but still achieved an outperforming performance in all 10 imbalanced datasets. The source code is available in https://github.com/antoniosehk/WSDeepNN.",
isbn="978-3-319-59876-5"
}

@inproceedings{Sachin2017,
  title={Optimization as a model for few-shot learning},
  author={Ravi, Sachin and Larochelle, Hugo},
  booktitle={In International Conference on Learning Representations (ICLR)},
  year={2017}
}

@ARTICLE{Chawla02smote:synthetic,
    author = {Nitesh V. Chawla and Kevin W. Bowyer and Lawrence O. Hall and W. Philip Kegelmeyer},
    title = {{SMOTE: Synthetic Minority Over-sampling Technique}},
    journal = {Journal of Artificial Intelligence Research},
    year = {2002},
    volume = {16},
    pages = {321--357}
}

@inproceedings{Ting:2000:CSC:645529.657944,
 author = {Ting, Kai Ming},
 title = {A Comparative Study of Cost-Sensitive Boosting Algorithms},
 booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
 series = {ICML '00},
 year = {2000},
 isbn = {1-55860-707-2},
 pages = {983--990},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645529.657944},
 acmid = {657944},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

